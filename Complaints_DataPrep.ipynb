{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09097758-70c3-4dbc-a387-ddb1c5683ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('complaints.json') \n",
    "import json\n",
    "import pandas as pd\n",
    "  \n",
    "# returns JSON object as  \n",
    "# a dictionary \n",
    "data = json.load(f)\n",
    "df=pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e0a7b0e-c1ed-45f5-98bd-c9a3e0b9e3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.2-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m855.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy) (59.3.0)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.7-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.6/126.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.9.1\n",
      "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.9\n",
      "  Downloading spacy_legacy-3.0.10-py2.py3-none-any.whl (21 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.8-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (4.42.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.28.1)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.3-py3-none-any.whl (9.3 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4\n",
      "  Downloading pydantic-1.9.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.21.6)\n",
      "Collecting typing-extensions<4.2.0,>=3.7.4\n",
      "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (458 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.8/458.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.2-py3-none-any.whl (27 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (20.1)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Downloading thinc-8.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (803 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.9/803.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy) (2.4.6)\n",
      "Collecting smart-open<6.0.0,>=5.2.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.0.1-py3-none-any.whl (32 kB)\n",
      "Collecting blis<0.10.0,>=0.7.8\n",
      "  Downloading blis-0.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting click<9.0.0,>=7.1.1\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy) (4.12.0)\n",
      "Installing collected packages: wasabi, cymem, typing-extensions, spacy-loggers, spacy-legacy, smart-open, murmurhash, langcodes, blis, pydantic, preshed, catalogue, srsly, click, typer, confection, thinc, pathy, spacy\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: Click 7.0\n",
      "    Uninstalling Click-7.0:\n",
      "      Successfully uninstalled Click-7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.3.4 requires botocore<1.24.22,>=1.24.21, but you have botocore 1.27.62 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed blis-0.9.1 catalogue-2.0.8 click-8.1.3 confection-0.0.1 cymem-2.0.6 langcodes-3.3.0 murmurhash-1.0.8 pathy-0.6.2 preshed-3.0.7 pydantic-1.9.2 smart-open-5.2.1 spacy-3.4.1 spacy-legacy-3.0.10 spacy-loggers-1.0.3 srsly-2.4.4 thinc-8.1.1 typer-0.4.2 typing-extensions-4.1.1 wasabi-0.10.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting en-core-web-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.1.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (20.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.42.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (59.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.28.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.8)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.14.0)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.4)\n",
      "Requirement already satisfied: blis<0.10.0,>=0.7.8 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.9.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.0.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.12.0)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "import json \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, nltk, spacy, string\n",
    "import en_core_web_sm\n",
    "import nltk \n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from plotly.offline import plot\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8ab2f31-67b8-4cca-85ba-b5ca82d449bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('complaints.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "159407e6-3c76-4a3c-84b4-7a4629f13d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78313, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f177356a-d5f1-46ba-a3b1-a90454fbe06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning new column names\n",
    "df.columns = [\"index\",\"type\",\"id\",\"score\",\"tags\",\"zip_code\",\"complaint_id\",\"issue\",\"date_received\",\"state\",\"consumer_disputed\",\"product\",\"company_response\",\"company\",\"submitted_via\",\"date_sent_to_company\",\"company_public_response\",\"sub_product\",\"timely\",\"complaint_what_happened\",\"sub_issue\",\"consumer_consent_provided\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cdced4e-6961-4a86-9664-680124f07ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning nan in place of blanks in the complaints column(complaint_what_happened)\n",
    "df[df['complaint_what_happened']==''] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e2689f9-4e53-49d5-9f58-8cd8fe8c2194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing all rows where complaints column is nan\n",
    "df=df.dropna(subset=['complaint_what_happened'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e7df16d-7e1d-42b7-b60c-74c83e62c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, nltk, spacy, string\n",
    "pd.options.mode.chained_assignment = None  \n",
    "df.complaint_what_happened=df.complaint_what_happened.astype(str)\n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "df_clean = pd.DataFrame(df.complaint_what_happened.apply(lambda x: clean_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4db41d3c-1a07-4560-bb75-3f6df25e6704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, nltk, spacy, string\n",
    "pd.options.mode.chained_assignment = None  \n",
    "df.complaint_what_happened=df.complaint_what_happened.astype(str)\n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "df_clean = pd.DataFrame(df.complaint_what_happened.apply(lambda x: clean_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8157b128-127b-404c-8ee3-d53e734c5560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Lemmatize the texts\n",
    "def lemmatizer(text):        \n",
    "    sent = []\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        sent.append(word.lemma_)\n",
    "    return \" \".join(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d727cf62-a670-4001-bf1a-098b1125dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe that will have only the complaints and the lemmatized complaints.\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "df_clean[\"Complaint_lemmatize\"] =  df_clean.apply(lambda x: lemmatizer(x['complaint_what_happened']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6527433a-d3db-4cb3-85f4-afc1db295c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29904344-66d4-4bf0-802c-efd8fd96e443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: TextBlob in /opt/conda/lib/python3.7/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/conda/lib/python3.7/site-packages (from TextBlob) (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk>=3.1->TextBlob) (2022.8.17)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk>=3.1->TextBlob) (4.42.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk>=3.1->TextBlob) (0.14.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk>=3.1->TextBlob) (8.1.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->nltk>=3.1->TextBlob) (4.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk>=3.1->TextBlob) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk>=3.1->TextBlob) (4.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Using custom Chunking\n",
    "#Chunking in NLP is a process to take small pieces of information and group them into large units. The primary use of Chunking is making groups of \"noun phrases.\n",
    "#Here we are using only noun, singular as we have already lemmatized the texts.\n",
    "import pandas as pd\n",
    "!pip install TextBlob\n",
    "from textblob import TextBlob\n",
    "nltk.download('punkt')\n",
    "\n",
    "def pos_tag(text):\n",
    "    try:\n",
    "        return TextBlob(text).tags\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_adjectives(text):\n",
    "    blob = TextBlob(text)\n",
    "    return ' '.join([ word for (word,tag) in blob.tags if tag == \"NN\"])\n",
    "\n",
    "df_clean[\"complaint_POS_removed\"] =  df_clean.apply(lambda x: get_adjectives(x['Complaint_lemmatize']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac6da3e2-1863-40d5-b613-d52c5219aeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_what_happened</th>\n",
       "      <th>Complaint_lemmatize</th>\n",
       "      <th>complaint_POS_removed</th>\n",
       "      <th>Complaint_clean</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good morning my name is xxxx xxxx and i apprec...</td>\n",
       "      <td>good morning my name be xxxx xxxx and I apprec...</td>\n",
       "      <td>morning name stop bank cardmember service ask ...</td>\n",
       "      <td>morning name stop bank cardmember service ask ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i upgraded my xxxx xxxx card in  and was told ...</td>\n",
       "      <td>I upgrade my xxxx xxxx card in   and be tell b...</td>\n",
       "      <td>card agent upgrade date agent information orde...</td>\n",
       "      <td>card agent upgrade date agent information orde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chase card was reported on  however fraudulent...</td>\n",
       "      <td>chase card be report on   however fraudulent a...</td>\n",
       "      <td>card report application identity consent servi...</td>\n",
       "      <td>card report application identity consent servi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>on  while trying to book a xxxx  xxxx  ticket ...</td>\n",
       "      <td>on   while try to book a xxxx   xxxx   ticket ...</td>\n",
       "      <td>try book xxxx ticket offer ticket card informa...</td>\n",
       "      <td>try book  ticket offer ticket card information...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>my grand son give me check for  i deposit it i...</td>\n",
       "      <td>my grand son give I check for   I deposit it i...</td>\n",
       "      <td>son chase account fund bank account pay money ...</td>\n",
       "      <td>son chase account fund bank account pay money ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78303</th>\n",
       "      <td>after being a chase card customer for well ove...</td>\n",
       "      <td>after be a chase card customer for well over a...</td>\n",
       "      <td>card customer decade solicitation credit card ...</td>\n",
       "      <td>card customer decade solicitation credit card ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78309</th>\n",
       "      <td>on wednesday xxxxxxxx i called chas my xxxx xx...</td>\n",
       "      <td>on wednesday xxxxxxxx I call chas my xxxx xxxx...</td>\n",
       "      <td>visa credit card provider claim purchase prote...</td>\n",
       "      <td>visa credit card provider claim purchase prote...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78310</th>\n",
       "      <td>i am not familiar with xxxx pay and did not un...</td>\n",
       "      <td>I be not familiar with xxxx pay and do not und...</td>\n",
       "      <td>pay risk provide consumer bank app chase year ...</td>\n",
       "      <td>pay risk provide consumer bank app chase year ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78311</th>\n",
       "      <td>i have had flawless credit for  yrs ive had ch...</td>\n",
       "      <td>I have have flawless credit for   yr I ve have...</td>\n",
       "      <td>credit yr credit card chase freedom xxxx probl...</td>\n",
       "      <td>credit yr credit card chase freedom  problem b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78312</th>\n",
       "      <td>roughly  years ago i closed out my accounts wi...</td>\n",
       "      <td>roughly   year ago I close out my account with...</td>\n",
       "      <td>year account jp bank xxxx order line credit ac...</td>\n",
       "      <td>year account jp bank  order line credit accoun...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21072 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 complaint_what_happened  \\\n",
       "1      good morning my name is xxxx xxxx and i apprec...   \n",
       "2      i upgraded my xxxx xxxx card in  and was told ...   \n",
       "10     chase card was reported on  however fraudulent...   \n",
       "11     on  while trying to book a xxxx  xxxx  ticket ...   \n",
       "14     my grand son give me check for  i deposit it i...   \n",
       "...                                                  ...   \n",
       "78303  after being a chase card customer for well ove...   \n",
       "78309  on wednesday xxxxxxxx i called chas my xxxx xx...   \n",
       "78310  i am not familiar with xxxx pay and did not un...   \n",
       "78311  i have had flawless credit for  yrs ive had ch...   \n",
       "78312  roughly  years ago i closed out my accounts wi...   \n",
       "\n",
       "                                     Complaint_lemmatize  \\\n",
       "1      good morning my name be xxxx xxxx and I apprec...   \n",
       "2      I upgrade my xxxx xxxx card in   and be tell b...   \n",
       "10     chase card be report on   however fraudulent a...   \n",
       "11     on   while try to book a xxxx   xxxx   ticket ...   \n",
       "14     my grand son give I check for   I deposit it i...   \n",
       "...                                                  ...   \n",
       "78303  after be a chase card customer for well over a...   \n",
       "78309  on wednesday xxxxxxxx I call chas my xxxx xxxx...   \n",
       "78310  I be not familiar with xxxx pay and do not und...   \n",
       "78311  I have have flawless credit for   yr I ve have...   \n",
       "78312  roughly   year ago I close out my account with...   \n",
       "\n",
       "                                   complaint_POS_removed  \\\n",
       "1      morning name stop bank cardmember service ask ...   \n",
       "2      card agent upgrade date agent information orde...   \n",
       "10     card report application identity consent servi...   \n",
       "11     try book xxxx ticket offer ticket card informa...   \n",
       "14     son chase account fund bank account pay money ...   \n",
       "...                                                  ...   \n",
       "78303  card customer decade solicitation credit card ...   \n",
       "78309  visa credit card provider claim purchase prote...   \n",
       "78310  pay risk provide consumer bank app chase year ...   \n",
       "78311  credit yr credit card chase freedom xxxx probl...   \n",
       "78312  year account jp bank xxxx order line credit ac...   \n",
       "\n",
       "                                         Complaint_clean  Topic  \n",
       "1      morning name stop bank cardmember service ask ...      0  \n",
       "2      card agent upgrade date agent information orde...      1  \n",
       "10     card report application identity consent servi...      1  \n",
       "11     try book  ticket offer ticket card information...      1  \n",
       "14     son chase account fund bank account pay money ...      0  \n",
       "...                                                  ...    ...  \n",
       "78303  card customer decade solicitation credit card ...      1  \n",
       "78309  visa credit card provider claim purchase prote...      3  \n",
       "78310  pay risk provide consumer bank app chase year ...      3  \n",
       "78311  credit yr credit card chase freedom  problem b...      2  \n",
       "78312  year account jp bank  order line credit accoun...      2  \n",
       "\n",
       "[21072 rows x 5 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bef6e220-f524-4528-a3e4-d9af5fd1e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing -PRON- from the text corpus\n",
    "df_clean['Complaint_clean'] = df_clean['complaint_POS_removed'].str.replace('-PRON-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5bc0b779-3d1b-4c82-afab-bea52aeecae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['Complaint_clean'] = df_clean['Complaint_clean'].str.replace('xxxx','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5316e95c-8809-4e1c-a6ef-96ccbc6f05d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_what_happened</th>\n",
       "      <th>Complaint_lemmatize</th>\n",
       "      <th>complaint_POS_removed</th>\n",
       "      <th>Complaint_clean</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good morning my name is xxxx xxxx and i apprec...</td>\n",
       "      <td>good morning my name be xxxx xxxx and I apprec...</td>\n",
       "      <td>morning name stop bank cardmember service ask ...</td>\n",
       "      <td>morning name stop bank cardmember service ask ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i upgraded my xxxx xxxx card in  and was told ...</td>\n",
       "      <td>I upgrade my xxxx xxxx card in   and be tell b...</td>\n",
       "      <td>card agent upgrade date agent information orde...</td>\n",
       "      <td>card agent upgrade date agent information orde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chase card was reported on  however fraudulent...</td>\n",
       "      <td>chase card be report on   however fraudulent a...</td>\n",
       "      <td>card report application identity consent servi...</td>\n",
       "      <td>card report application identity consent servi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>on  while trying to book a xxxx  xxxx  ticket ...</td>\n",
       "      <td>on   while try to book a xxxx   xxxx   ticket ...</td>\n",
       "      <td>try book xxxx ticket offer ticket card informa...</td>\n",
       "      <td>try book  ticket offer ticket card information...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>my grand son give me check for  i deposit it i...</td>\n",
       "      <td>my grand son give I check for   I deposit it i...</td>\n",
       "      <td>son chase account fund bank account pay money ...</td>\n",
       "      <td>son chase account fund bank account pay money ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78303</th>\n",
       "      <td>after being a chase card customer for well ove...</td>\n",
       "      <td>after be a chase card customer for well over a...</td>\n",
       "      <td>card customer decade solicitation credit card ...</td>\n",
       "      <td>card customer decade solicitation credit card ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78309</th>\n",
       "      <td>on wednesday xxxxxxxx i called chas my xxxx xx...</td>\n",
       "      <td>on wednesday xxxxxxxx I call chas my xxxx xxxx...</td>\n",
       "      <td>visa credit card provider claim purchase prote...</td>\n",
       "      <td>visa credit card provider claim purchase prote...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78310</th>\n",
       "      <td>i am not familiar with xxxx pay and did not un...</td>\n",
       "      <td>I be not familiar with xxxx pay and do not und...</td>\n",
       "      <td>pay risk provide consumer bank app chase year ...</td>\n",
       "      <td>pay risk provide consumer bank app chase year ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78311</th>\n",
       "      <td>i have had flawless credit for  yrs ive had ch...</td>\n",
       "      <td>I have have flawless credit for   yr I ve have...</td>\n",
       "      <td>credit yr credit card chase freedom xxxx probl...</td>\n",
       "      <td>credit yr credit card chase freedom  problem b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78312</th>\n",
       "      <td>roughly  years ago i closed out my accounts wi...</td>\n",
       "      <td>roughly   year ago I close out my account with...</td>\n",
       "      <td>year account jp bank xxxx order line credit ac...</td>\n",
       "      <td>year account jp bank  order line credit accoun...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21072 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 complaint_what_happened  \\\n",
       "1      good morning my name is xxxx xxxx and i apprec...   \n",
       "2      i upgraded my xxxx xxxx card in  and was told ...   \n",
       "10     chase card was reported on  however fraudulent...   \n",
       "11     on  while trying to book a xxxx  xxxx  ticket ...   \n",
       "14     my grand son give me check for  i deposit it i...   \n",
       "...                                                  ...   \n",
       "78303  after being a chase card customer for well ove...   \n",
       "78309  on wednesday xxxxxxxx i called chas my xxxx xx...   \n",
       "78310  i am not familiar with xxxx pay and did not un...   \n",
       "78311  i have had flawless credit for  yrs ive had ch...   \n",
       "78312  roughly  years ago i closed out my accounts wi...   \n",
       "\n",
       "                                     Complaint_lemmatize  \\\n",
       "1      good morning my name be xxxx xxxx and I apprec...   \n",
       "2      I upgrade my xxxx xxxx card in   and be tell b...   \n",
       "10     chase card be report on   however fraudulent a...   \n",
       "11     on   while try to book a xxxx   xxxx   ticket ...   \n",
       "14     my grand son give I check for   I deposit it i...   \n",
       "...                                                  ...   \n",
       "78303  after be a chase card customer for well over a...   \n",
       "78309  on wednesday xxxxxxxx I call chas my xxxx xxxx...   \n",
       "78310  I be not familiar with xxxx pay and do not und...   \n",
       "78311  I have have flawless credit for   yr I ve have...   \n",
       "78312  roughly   year ago I close out my account with...   \n",
       "\n",
       "                                   complaint_POS_removed  \\\n",
       "1      morning name stop bank cardmember service ask ...   \n",
       "2      card agent upgrade date agent information orde...   \n",
       "10     card report application identity consent servi...   \n",
       "11     try book xxxx ticket offer ticket card informa...   \n",
       "14     son chase account fund bank account pay money ...   \n",
       "...                                                  ...   \n",
       "78303  card customer decade solicitation credit card ...   \n",
       "78309  visa credit card provider claim purchase prote...   \n",
       "78310  pay risk provide consumer bank app chase year ...   \n",
       "78311  credit yr credit card chase freedom xxxx probl...   \n",
       "78312  year account jp bank xxxx order line credit ac...   \n",
       "\n",
       "                                         Complaint_clean  Topic  \n",
       "1      morning name stop bank cardmember service ask ...      0  \n",
       "2      card agent upgrade date agent information orde...      1  \n",
       "10     card report application identity consent servi...      1  \n",
       "11     try book  ticket offer ticket card information...      1  \n",
       "14     son chase account fund bank account pay money ...      0  \n",
       "...                                                  ...    ...  \n",
       "78303  card customer decade solicitation credit card ...      1  \n",
       "78309  visa credit card provider claim purchase prote...      3  \n",
       "78310  pay risk provide consumer bank app chase year ...      3  \n",
       "78311  credit yr credit card chase freedom  problem b...      2  \n",
       "78312  year account jp bank  order line credit accoun...      2  \n",
       "\n",
       "[21072 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be010c12-3daf-4768-813c-69007db3bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "74c36fae-1b5e-4150-a4df-3763a94346e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = tfidf.fit_transform(df_clean['Complaint_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14a9b286-02c4-41f4-a6e3-f4766e18f561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==4.1.0\n",
      "  Downloading gensim-4.1.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.7/site-packages (from gensim==4.1.0) (1.21.6)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim==4.1.0) (1.4.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim==4.1.0) (5.2.1)\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m5\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "!pip install gensim==4.1.0\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.nmf import Nmf\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from operator import itemgetter\n",
    "# Use Gensim's NMF to get the best num of topics via coherence score\n",
    "texts = df_clean['Complaint_clean']\n",
    "dataset = [d.split() for d in texts]\n",
    "\n",
    "# Create a dictionary\n",
    "# In gensim a dictionary is a mapping between words and their integer id\n",
    "dictionary = Dictionary(dataset)\n",
    "\n",
    "# Filter out extremes to limit the number of features\n",
    "dictionary.filter_extremes(\n",
    "    no_below=3,\n",
    "    no_above=0.85,\n",
    "    keep_n=5000\n",
    ")\n",
    "\n",
    "# Create the bag-of-words format (list of (token_id, token_count))\n",
    "corpus = [dictionary.doc2bow(text) for text in dataset]\n",
    "\n",
    "# Create a list of the topic numbers we want to try\n",
    "topic_nums = list(np.arange(5, 10, 1))\n",
    "\n",
    "# Run the nmf model and calculate the coherence score\n",
    "# for each number of topics\n",
    "coherence_scores = []\n",
    "\n",
    "for num in topic_nums:\n",
    "    nmf = Nmf(\n",
    "        corpus=corpus,\n",
    "        num_topics=num,\n",
    "        id2word=dictionary,\n",
    "        chunksize=2000,\n",
    "        passes=5,\n",
    "        kappa=.1,\n",
    "        minimum_probability=0.01,\n",
    "        w_max_iter=300,\n",
    "        w_stop_condition=0.0001,\n",
    "        h_max_iter=100,\n",
    "        h_stop_condition=0.001,\n",
    "        eval_every=10,\n",
    "        normalize=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Run the coherence model to get the score\n",
    "    cm = CoherenceModel(\n",
    "        model=nmf,\n",
    "        texts=texts,\n",
    "        dictionary=dictionary,\n",
    "        #coherence='c_v'\n",
    "    )\n",
    "    \n",
    "    coherence_scores.append(round(cm.get_coherence(), 5))\n",
    "\n",
    "# Get the number of topics with the highest coherence score\n",
    "scores = list(zip(topic_nums, coherence_scores))\n",
    "best_num_topics = sorted(scores, key=itemgetter(1), reverse=True)[0][0]\n",
    "\n",
    "print(best_num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f7009bf9-0940-46fe-98c3-d241ab890e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "nmf_model = NMF(n_components=5,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb14e188-721a-47e2-b70d-95e726295349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7257"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model.fit(dtm)\n",
    "len(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f47df6e-0669-4c46-8fa0-97027b6529d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number\n",
      "day\n",
      "branch\n",
      "deposit\n",
      "chase\n",
      "fund\n",
      "money\n",
      "check\n",
      "bank\n",
      "account\n"
     ]
    }
   ],
   "source": [
    "#Print the top word of a sample component\n",
    "single_topic = nmf_model.components_[0]\n",
    "single_topic.argsort()\n",
    "top_word_indices = single_topic.argsort()[-10:]\n",
    "for index in top_word_indices:\n",
    "    print(tfidf.get_feature_names()[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "daa91467-f926-41bf-bca0-b430942f1be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 15 WORDS FOR TOPIC #0\n",
      "['transfer', 'claim', 'checking', 'transaction', 'business', 'number', 'day', 'branch', 'deposit', 'chase', 'fund', 'money', 'check', 'bank', 'account']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #1\n",
      "['balance', 'year', 'letter', 'application', 'debt', 'information', 'limit', 'company', 'score', 'account', 'chase', 'inquiry', 'report', 'card', 'credit']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #2\n",
      "['mortgage', 'year', 'chase', 'account', 'credit', 'pay', 'date', 'auto', 'time', 'day', 'statement', 'fee', 'month', 'balance', 'payment']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #3\n",
      "['company', 'refund', 'statement', 'time', 'service', 'claim', 'purchase', 'fraud', 'merchant', 'chase', 'dispute', 'transaction', 'fee', 'card', 'charge']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #4\n",
      "['sale', 'foreclosure', 'house', 'bank', 'document', 'time', 'rate', 'letter', 'year', 'property', 'chase', 'modification', 'home', 'mortgage', 'loan']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print Top15 words for each of the topics\n",
    "for index,topic in enumerate(nmf_model.components_):\n",
    "    print(f'THE TOP 15 WORDS FOR TOPIC #{index}')\n",
    "    print([tfidf.get_feature_names()[i] for i in topic.argsort()[-15:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "294207a9-085f-454f-94fc-09039480dbd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 3, 2, 2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the best topic for each complaint\n",
    "topic_results = nmf_model.transform(dtm)\n",
    "topic_results[0].round(2)\n",
    "topic_results[0].argmax()\n",
    "topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "52d92a26-e7d8-47d5-84f4-38a3a96efc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign the best topic to each of the cmplaints in Topic Column\n",
    "df_clean['Topic'] = topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3746c852-4f72-4685-9330-884d98006e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dictionary of Topic names and Topics\n",
    "Topic_names = {0:\"Bank Account services\",1:\"Credit card or prepaid card\", 2:\"Others\",3:\"Theft/Dispute Reporting\",4:\"Mortgage/Loan\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "17079f82-da2e-43c8-bccb-bf5170122df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace Topics with Topic Names\n",
    "df_clean['Topic'] = df_clean['Topic'].map(Topic_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "883b3991-2bec-42a2-88ff-ed685f0c3c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_what_happened</th>\n",
       "      <th>Complaint_lemmatize</th>\n",
       "      <th>complaint_POS_removed</th>\n",
       "      <th>Complaint_clean</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good morning my name is xxxx xxxx and i apprec...</td>\n",
       "      <td>good morning my name be xxxx xxxx and I apprec...</td>\n",
       "      <td>morning name stop bank cardmember service ask ...</td>\n",
       "      <td>morning name stop bank cardmember service ask ...</td>\n",
       "      <td>Bank Account services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i upgraded my xxxx xxxx card in  and was told ...</td>\n",
       "      <td>I upgrade my xxxx xxxx card in   and be tell b...</td>\n",
       "      <td>card agent upgrade date agent information orde...</td>\n",
       "      <td>card agent upgrade date agent information orde...</td>\n",
       "      <td>Credit card or prepaid card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chase card was reported on  however fraudulent...</td>\n",
       "      <td>chase card be report on   however fraudulent a...</td>\n",
       "      <td>card report application identity consent servi...</td>\n",
       "      <td>card report application identity consent servi...</td>\n",
       "      <td>Credit card or prepaid card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>on  while trying to book a xxxx  xxxx  ticket ...</td>\n",
       "      <td>on   while try to book a xxxx   xxxx   ticket ...</td>\n",
       "      <td>try book xxxx ticket offer ticket card informa...</td>\n",
       "      <td>try book  ticket offer ticket card information...</td>\n",
       "      <td>Credit card or prepaid card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>my grand son give me check for  i deposit it i...</td>\n",
       "      <td>my grand son give I check for   I deposit it i...</td>\n",
       "      <td>son chase account fund bank account pay money ...</td>\n",
       "      <td>son chase account fund bank account pay money ...</td>\n",
       "      <td>Bank Account services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78303</th>\n",
       "      <td>after being a chase card customer for well ove...</td>\n",
       "      <td>after be a chase card customer for well over a...</td>\n",
       "      <td>card customer decade solicitation credit card ...</td>\n",
       "      <td>card customer decade solicitation credit card ...</td>\n",
       "      <td>Credit card or prepaid card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78309</th>\n",
       "      <td>on wednesday xxxxxxxx i called chas my xxxx xx...</td>\n",
       "      <td>on wednesday xxxxxxxx I call chas my xxxx xxxx...</td>\n",
       "      <td>visa credit card provider claim purchase prote...</td>\n",
       "      <td>visa credit card provider claim purchase prote...</td>\n",
       "      <td>Theft/Dispute Reporting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78310</th>\n",
       "      <td>i am not familiar with xxxx pay and did not un...</td>\n",
       "      <td>I be not familiar with xxxx pay and do not und...</td>\n",
       "      <td>pay risk provide consumer bank app chase year ...</td>\n",
       "      <td>pay risk provide consumer bank app chase year ...</td>\n",
       "      <td>Theft/Dispute Reporting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78311</th>\n",
       "      <td>i have had flawless credit for  yrs ive had ch...</td>\n",
       "      <td>I have have flawless credit for   yr I ve have...</td>\n",
       "      <td>credit yr credit card chase freedom xxxx probl...</td>\n",
       "      <td>credit yr credit card chase freedom  problem b...</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78312</th>\n",
       "      <td>roughly  years ago i closed out my accounts wi...</td>\n",
       "      <td>roughly   year ago I close out my account with...</td>\n",
       "      <td>year account jp bank xxxx order line credit ac...</td>\n",
       "      <td>year account jp bank  order line credit accoun...</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21072 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 complaint_what_happened  \\\n",
       "1      good morning my name is xxxx xxxx and i apprec...   \n",
       "2      i upgraded my xxxx xxxx card in  and was told ...   \n",
       "10     chase card was reported on  however fraudulent...   \n",
       "11     on  while trying to book a xxxx  xxxx  ticket ...   \n",
       "14     my grand son give me check for  i deposit it i...   \n",
       "...                                                  ...   \n",
       "78303  after being a chase card customer for well ove...   \n",
       "78309  on wednesday xxxxxxxx i called chas my xxxx xx...   \n",
       "78310  i am not familiar with xxxx pay and did not un...   \n",
       "78311  i have had flawless credit for  yrs ive had ch...   \n",
       "78312  roughly  years ago i closed out my accounts wi...   \n",
       "\n",
       "                                     Complaint_lemmatize  \\\n",
       "1      good morning my name be xxxx xxxx and I apprec...   \n",
       "2      I upgrade my xxxx xxxx card in   and be tell b...   \n",
       "10     chase card be report on   however fraudulent a...   \n",
       "11     on   while try to book a xxxx   xxxx   ticket ...   \n",
       "14     my grand son give I check for   I deposit it i...   \n",
       "...                                                  ...   \n",
       "78303  after be a chase card customer for well over a...   \n",
       "78309  on wednesday xxxxxxxx I call chas my xxxx xxxx...   \n",
       "78310  I be not familiar with xxxx pay and do not und...   \n",
       "78311  I have have flawless credit for   yr I ve have...   \n",
       "78312  roughly   year ago I close out my account with...   \n",
       "\n",
       "                                   complaint_POS_removed  \\\n",
       "1      morning name stop bank cardmember service ask ...   \n",
       "2      card agent upgrade date agent information orde...   \n",
       "10     card report application identity consent servi...   \n",
       "11     try book xxxx ticket offer ticket card informa...   \n",
       "14     son chase account fund bank account pay money ...   \n",
       "...                                                  ...   \n",
       "78303  card customer decade solicitation credit card ...   \n",
       "78309  visa credit card provider claim purchase prote...   \n",
       "78310  pay risk provide consumer bank app chase year ...   \n",
       "78311  credit yr credit card chase freedom xxxx probl...   \n",
       "78312  year account jp bank xxxx order line credit ac...   \n",
       "\n",
       "                                         Complaint_clean  \\\n",
       "1      morning name stop bank cardmember service ask ...   \n",
       "2      card agent upgrade date agent information orde...   \n",
       "10     card report application identity consent servi...   \n",
       "11     try book  ticket offer ticket card information...   \n",
       "14     son chase account fund bank account pay money ...   \n",
       "...                                                  ...   \n",
       "78303  card customer decade solicitation credit card ...   \n",
       "78309  visa credit card provider claim purchase prote...   \n",
       "78310  pay risk provide consumer bank app chase year ...   \n",
       "78311  credit yr credit card chase freedom  problem b...   \n",
       "78312  year account jp bank  order line credit accoun...   \n",
       "\n",
       "                             Topic  \n",
       "1            Bank Account services  \n",
       "2      Credit card or prepaid card  \n",
       "10     Credit card or prepaid card  \n",
       "11     Credit card or prepaid card  \n",
       "14           Bank Account services  \n",
       "...                            ...  \n",
       "78303  Credit card or prepaid card  \n",
       "78309      Theft/Dispute Reporting  \n",
       "78310      Theft/Dispute Reporting  \n",
       "78311                       Others  \n",
       "78312                       Others  \n",
       "\n",
       "[21072 rows x 5 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "beaf9786-2fc4-4101-a90c-51d70a5abe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('complaintsclean.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a227c747-99dd-4c09-871c-ca47af8fab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "Topic_names = {\"Bank Account services\":0,\"Credit card or prepaid card\":1,\"Others\":2,\"Theft/Dispute Reporting\":3,\"Mortgage/Loan\":4}\n",
    "df_clean['Topic'] = df_clean['Topic'].map(Topic_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "045a65de-0522-4068-93ae-19254dbd310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=df_clean[[\"complaint_what_happened\",\"Topic\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d8609ee1-33bf-4e39-8a81-ce18c95e1b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('complaintsTraining.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a798dcda-994c-407d-aba3-2de76031214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e0780d39-7147-4aa6-b267-30a96bf033c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('complaintsTraining.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4a5b0bf7-a650-448f-ac74-0515a92fd5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=data[[\"complaint_what_happened\",\"Topic\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e16bfc7f-153a-434f-b0c1-fed130a82c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_what_happened</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good morning my name is xxxx xxxx and i apprec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i upgraded my xxxx xxxx card in  and was told ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chase card was reported on  however fraudulent...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>on  while trying to book a xxxx  xxxx  ticket ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my grand son give me check for  i deposit it i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21067</th>\n",
       "      <td>after being a chase card customer for well ove...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21068</th>\n",
       "      <td>on wednesday xxxxxxxx i called chas my xxxx xx...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21069</th>\n",
       "      <td>i am not familiar with xxxx pay and did not un...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21070</th>\n",
       "      <td>i have had flawless credit for  yrs ive had ch...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21071</th>\n",
       "      <td>roughly  years ago i closed out my accounts wi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21072 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 complaint_what_happened  Topic\n",
       "0      good morning my name is xxxx xxxx and i apprec...      0\n",
       "1      i upgraded my xxxx xxxx card in  and was told ...      1\n",
       "2      chase card was reported on  however fraudulent...      1\n",
       "3      on  while trying to book a xxxx  xxxx  ticket ...      1\n",
       "4      my grand son give me check for  i deposit it i...      0\n",
       "...                                                  ...    ...\n",
       "21067  after being a chase card customer for well ove...      1\n",
       "21068  on wednesday xxxxxxxx i called chas my xxxx xx...      3\n",
       "21069  i am not familiar with xxxx pay and did not un...      3\n",
       "21070  i have had flawless credit for  yrs ive had ch...      2\n",
       "21071  roughly  years ago i closed out my accounts wi...      2\n",
       "\n",
       "[21072 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0a242c2b-41ce-41fb-a39a-96b2f40b9c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.to_csv('complaintssharpened.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "926ee636-bab3-4007-ac7d-0605742b19a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "#GET VECTOR COUNT\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(training_data['complaint_what_happened'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "026e043d-b235-4d3f-ae8f-b23c7b5a5ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<21072x33599 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2280810 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c6fb41dc-9ada-4f0e-919d-359649608726",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(count_vect.vocabulary_, open(\"count_vector.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "623edacd-7c67-4480-96cf-55d115db2d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#TRANSFORM WORD VECTOR TO TF IDF\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2f338e65-1202-44c1-aa35-594b2172c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame()\n",
    "test=tfidf_transformer.fit(X_train_counts)\n",
    "for i in range(1000):\n",
    "    df=df.append(pd.DataFrame(X_train_tfidf[i].todense()))\n",
    "#df[1,33599]=pd.DataFrame(X_train_tfidf[1].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cdbb8fa1-9694-4383-bc23-fc2d28c5b13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df.to_csv(\"tfidf_features.csv\",encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2a71a9cd-7c9c-4584-8c0d-b524f3a8b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.assign(lables=training_data[:1000]['Topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7e1f8e46-def7-4d3f-ba71-82d2a7c406c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lables'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "61bcf6e5-92b7-4e60-a883-39a0df7aa569",
   "metadata": {},
   "outputs": [],
   "source": [
    "ylabel=training_data[:1000]['Topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "73848049-b4f6-4009-b512-beaa9800b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.assign(lables=ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "df6fd87f-7e43-47f6-9e48-abb4090c81e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1754"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ylabel.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "88ec7559-1886-4d72-86d1-52d12e022f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lables']=ylabel.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9b0a951f-bf94-46e6-be66-6a727000926e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1754"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lables'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4097969d-7b07-4111-b18a-e64f74d0c067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c08e0156-789b-4f39-9f20-4fd6879bd993",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tfidffeatureswithlables.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e90c2b74-4fd4-4953-bbc9-615ecb3ccce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "21067    1\n",
       "21068    3\n",
       "21069    3\n",
       "21070    2\n",
       "21071    2\n",
       "Name: Topic, Length: 21072, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['Topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c5fe094d-a4a2-40b1-b16c-313d65bec06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>1.069152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>1.078758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1.082462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>1.133416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chase</th>\n",
       "      <td>1.169187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>egfects</th>\n",
       "      <td>10.262601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persecute</th>\n",
       "      <td>10.262601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persaonl</th>\n",
       "      <td>10.262601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persigned</th>\n",
       "      <td>10.262601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoomed</th>\n",
       "      <td>10.262601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33599 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           idf_weights\n",
       "to            1.069152\n",
       "and           1.078758\n",
       "the           1.082462\n",
       "my            1.133416\n",
       "chase         1.169187\n",
       "...                ...\n",
       "egfects      10.262601\n",
       "persecute    10.262601\n",
       "persaonl     10.262601\n",
       "persigned    10.262601\n",
       "zoomed       10.262601\n",
       "\n",
       "[33599 rows x 1 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test\n",
    "df_idf = pd.DataFrame(test.idf_, index=count_vect.get_feature_names(),columns=[\"idf_weights\"]) \n",
    "# sort ascending \n",
    "df_idf.sort_values(by=['idf_weights'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d0a35491-74bb-47b1-b4be-5227bcafa238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "74094cb6-0e37-450f-b5bc-3c133c031346",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df.lables, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d5019581-9b59-4545-bd3f-7ff831d78448",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train[X_train.columns[-1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "09c7936a-a524-4e51-8414-f491ccf88f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 33599)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4f7848bc-64cd-4eeb-878a-81052848b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_test[X_test.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "39f2316d-e623-4024-ab55-a4bac7d9ddd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 33599)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ebe29182-35c3-47f3-94db-a4681319048d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 0    1\n",
       "0    3\n",
       "0    0\n",
       "0    0\n",
       "0    0\n",
       "    ..\n",
       "0    0\n",
       "0    0\n",
       "0    0\n",
       "0    1\n",
       "0    4\n",
       "Name: lables, Length: 750, dtype: int64>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9e6792ac-f34b-4f86-8b75-5aea00dc15ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv('y_train_features.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1a43608a-4c3b-45e3-ab50-498796f2704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv('y_test_features.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3e9be8a6-6527-484c-8b68-eca2bb04c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('X_train_features.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0115f62c-7cf5-41b3-b8aa-8619d76c02b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('X_test_features.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1336fb05-e6ba-4ecd-98ad-3749135ae9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma=pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6dbc8d-497b-4431-af37-52678d3dc5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e704aeb-f41a-47d0-8843-bf00b04f59bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.View()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d4ee15-bda3-4516-947c-61dac5ed5bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df0180d-872b-4126-be65-eb81abc56f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb5abe6-bea2-4d5f-80d7-aad468e2efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9a4cfa-61ca-4af6-97cf-ee022de4aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma.to_csv('ma.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb00015-8305-4fef-a837-7d3a5a3a71d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
